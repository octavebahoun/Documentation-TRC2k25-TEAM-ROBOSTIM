---
title: Template Documentation IA
sidebar_label: Template IA
---

import InfoCard from '@site/src/components/InfoCard';
import FeatureGrid from '@site/src/components/FeatureGrid';
import Table from '@site/src/components/Table';


# ğŸ§  Template de Documentation Technique - PÃ´le IA

> **ğŸ“‹ Guide d'utilisation** : Ce template vous aide Ã  crÃ©er une documentation technique complÃ¨te pour les tests et dÃ©veloppements en Intelligence Artificielle. Copiez ce fichier et remplissez les sections selon vos besoins.

---

## ğŸ“ Structure du Document

### 1. Imports nÃ©cessaires (en haut du fichier)

### 2. Frontmatter (mÃ©tadonnÃ©es)
```markdown
---
id: nom-du-test
title: Nom du Test - Description
sidebar_label: Nom court
---
```

---

## ğŸ“– Exemple Complet de Documentation

```jsx

sidebar_label: Test YOLO
---

# ğŸ§  Test DÃ©tection d'Objets avec YOLO

## PrÃ©sentation <span className="badge-sticker badge-it">ğŸ§  IA</span>

<InfoCard type="info" title="AperÃ§u du test" icon="ğŸ“·">
ImplÃ©mentation et validation d'un modÃ¨le de dÃ©tection d'objets en temps rÃ©el utilisant YOLOv8 pour la reconnaissance d'objets sur le robot.
</InfoCard>

## ğŸ“‹ Objectif du test

DÃ©crire l'objectif principal du test IA.

**Exemple** :
Valider la performance d'un modÃ¨le de dÃ©tection d'objets YOLOv8 pour identifier et localiser des objets dans l'environnement du robot en temps rÃ©el.

## ğŸ¯ CritÃ¨res de rÃ©ussite

- **PrÃ©cision (mAP)** : >80% sur le dataset de test
- **Temps d'infÃ©rence** : <50ms par image
- **Taux de dÃ©tection** : >90% pour les objets cibles
- **Faux positifs** : <5%

## ğŸ› ï¸ MatÃ©riel et Logiciel requis

### MatÃ©riel
- **GPU** : NVIDIA GTX 1060 ou supÃ©rieur (optionnel pour entraÃ®nement)
- **CPU** : Intel i5 ou Ã©quivalent
- **RAM** : 8GB minimum, 16GB recommandÃ©
- **CamÃ©ra** : USB 3.0 ou camÃ©ra Raspberry Pi

### Logiciel
- **Python** : 3.8+
- **PyTorch** : 2.0+
- **OpenCV** : 4.5+
- **Ultralytics YOLO** : 8.0+
- **ONNX Runtime** : 1.15+ (pour dÃ©ploiement)

## ğŸ“Š Architecture du ModÃ¨le

### Pipeline de traitement

<FeatureGrid items={[
  {icon:"ğŸ“·", title:"Capture", description:"Acquisition d'image depuis la camÃ©ra"},
  {icon:"ğŸ”„", title:"PrÃ©traitement", description:"Redimensionnement et normalisation"},
  {icon:"ğŸ§ ", title:"InfÃ©rence", description:"PrÃ©diction avec le modÃ¨le YOLO"},
  {icon:"ğŸ“Š", title:"Post-traitement", description:"Filtrage et visualisation des rÃ©sultats"}
]} />

### Outils et Librairies

<Table headers={["Librairie", "Version", "Usage"]}
  data={[
    ["PyTorch", "2.0+", "EntraÃ®nement et infÃ©rence"],
    ["OpenCV", "4.5+", "Traitement d'images"],
    ["Ultralytics", "8.0+", "ModÃ¨le YOLO"],
    ["ONNX Runtime", "1.15+", "DÃ©ploiement optimisÃ©"],
    ["NumPy", "1.24+", "Calculs numÃ©riques"]
  ]}
/>

## ğŸ“Š ProcÃ©dure de test

### Ã‰tape 1 : Installation des dÃ©pendances

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install torch torchvision
pip install ultralytics
pip install opencv-python
pip install onnxruntime
pip install numpy
```

### Ã‰tape 2 : PrÃ©paration du dataset

```python
# Structure du dataset
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

**Script de prÃ©paration** :
```python
from pathlib import Path
import shutil

def prepare_dataset(source_dir, target_dir):
    """Organise le dataset pour YOLO"""
    for split in ['train', 'val', 'test']:
        (target_dir / split / 'images').mkdir(parents=True, exist_ok=True)
        (target_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
    
    # Copier les fichiers selon votre logique
    # ...
```

### Ã‰tape 3 : EntraÃ®nement du modÃ¨le

```python
from ultralytics import YOLO

# Charger un modÃ¨le prÃ©-entraÃ®nÃ©
model = YOLO('yolov8n.pt')  # nano version pour vitesse

# EntraÃ®ner le modÃ¨le
results = model.train(
    data='dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device='cuda'  # ou 'cpu'
)
```

### Ã‰tape 4 : Ã‰valuation du modÃ¨le

```python
# Ã‰valuer sur le dataset de test
metrics = model.val(data='dataset.yaml')

print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
print(f"Precision: {metrics.box.mp}")
print(f"Recall: {metrics.box.mr}")
```

### Ã‰tape 5 : Test en temps rÃ©el

```python
import cv2
from ultralytics import YOLO

# Charger le modÃ¨le entraÃ®nÃ©
model = YOLO('best.pt')

# Capturer depuis la camÃ©ra
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # InfÃ©rence
    results = model(frame)
    
    # Visualiser les rÃ©sultats
    annotated_frame = results[0].plot()
    cv2.imshow('YOLO Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## ğŸ“ˆ RÃ©sultats attendus

### MÃ©triques de performance

<Table headers={["MÃ©trique", "Valeur cible", "Valeur mesurÃ©e", "Statut"]}
  data={[
    ["mAP@0.5", ">80%", "82.5%", "âœ…"],
    ["mAP@0.5:0.95", ">60%", "65.3%", "âœ…"],
    ["Temps infÃ©rence (CPU)", "<100ms", "85ms", "âœ…"],
    ["Temps infÃ©rence (GPU)", "<50ms", "35ms", "âœ…"],
    ["FPS", ">10", "12", "âœ…"]
  ]}
/>

### Matrice de confusion

**Exemple de visualisation** :
```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calculer la matrice de confusion
cm = confusion_matrix(y_true, y_pred)

# Visualiser
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de confusion')
plt.ylabel('Vraies classes')
plt.xlabel('Classes prÃ©dites')
plt.show()
```

## ğŸ” Validation des rÃ©sultats

### Analyse des performances

**Script d'analyse** :
```python
import matplotlib.pyplot as plt
import numpy as np

# DonnÃ©es de test
epochs = np.arange(1, 101)
train_loss = np.load('train_loss.npy')
val_loss = np.load('val_loss.npy')
map_scores = np.load('map_scores.npy')

# Graphique de la perte
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Ã‰volution de la perte')
plt.legend()
plt.grid(True)

# Graphique du mAP
plt.subplot(1, 2, 2)
plt.plot(epochs, map_scores)
plt.xlabel('Epochs')
plt.ylabel('mAP@0.5')
plt.title('Ã‰volution de la prÃ©cision')
plt.grid(True)

plt.tight_layout()
plt.show()
```

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants

#### 1. ModÃ¨le ne converge pas
- VÃ©rifier la qualitÃ© du dataset
- Ajuster le learning rate
- VÃ©rifier l'augmentation de donnÃ©es
- ContrÃ´ler le batch size

#### 2. Temps d'infÃ©rence trop lent
```python
# Optimiser avec ONNX
from ultralytics import YOLO

model = YOLO('best.pt')
model.export(format='onnx', simplify=True)

# Utiliser ONNX Runtime
import onnxruntime as ort
session = ort.InferenceSession('best.onnx')
```

#### 3. Faux positifs Ã©levÃ©s
- Augmenter le seuil de confiance
- AmÃ©liorer le dataset d'entraÃ®nement
- Utiliser data augmentation
- Ajuster les hyperparamÃ¨tres

### Commandes de diagnostic

```python
# VÃ©rifier les performances du modÃ¨le
model.info()

# Tester sur une image
results = model('test_image.jpg')
results[0].show()

# Exporter les rÃ©sultats
results[0].save('output.jpg')
```

## ğŸ“ Rapport de test

### RÃ©sumÃ© des performances
- **DurÃ©e d'entraÃ®nement** : [X] heures
- **Nombre d'Ã©poques** : [X]
- **Taille du dataset** : [X] images
- **mAP final** : [X]%
- **Temps d'infÃ©rence moyen** : [X]ms

### Recommandations
1. **Optimisation** : Convertir en ONNX pour dÃ©ploiement
2. **AmÃ©lioration** : Augmenter la taille du dataset
3. **Monitoring** : Surveiller la dÃ©rive du modÃ¨le
4. **Mise Ã  jour** : RÃ©entraÃ®ner rÃ©guliÃ¨rement avec de nouvelles donnÃ©es

## ğŸ”„ Tests de suivi

### ScÃ©narios de test
- Test sur images statiques
- Test en temps rÃ©el avec camÃ©ra
- Test de robustesse (Ã©clairage variable)
- Test de gÃ©nÃ©ralisation (nouvelles scÃ¨nes)

### MÃ©triques Ã  surveiller
- PrÃ©cision (mAP)
- Temps d'infÃ©rence
- Taux de faux positifs
- Utilisation mÃ©moire/GPU

---

## ğŸ“¸ Ajout d'images et visualisations

Pour ajouter des images, placez-les dans `static/img/` :

```markdown
![RÃ©sultats de dÃ©tection](/img/yolo-detection-results.png)
![Courbe d'entraÃ®nement](/img/training-curves.png)
![Matrice de confusion](/img/confusion-matrix.png)
```

## ğŸ”— Liens utiles

- [Documentation Ultralytics YOLO](https://docs.ultralytics.com/)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [OpenCV Tutorials](https://docs.opencv.org/)
- [ONNX Runtime](https://onnxruntime.ai/)

---

## ğŸ’¡ Composants React disponibles

### InfoCard
```jsx
<InfoCard type="info" title="Titre" icon="ğŸ“·">
Contenu de la carte d'information
</InfoCard>
```

Types disponibles : `info`, `warning`, `success`, `danger`

### FeatureGrid
```jsx
<FeatureGrid items={[
  {icon:"ğŸ“·", title:"Titre 1", description:"Description 1"},
  {icon:"ğŸ§ ", title:"Titre 2", description:"Description 2"}
]} />
```

### Table
```jsx
<Table headers={["MÃ©trique", "Valeur"]}
  data={[
    ["mAP@0.5", "82.5%"],
    ["FPS", "12"]
  ]}
/>
```

---

*Template crÃ©Ã© le : [Date]*
*DerniÃ¨re mise Ã  jour : [Date]*
*Statut : âœ… Template prÃªt Ã  l'emploi*
